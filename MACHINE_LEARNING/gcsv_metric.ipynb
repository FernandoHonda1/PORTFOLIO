{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# em cima do dataset 'spam_ham.csv', seleciono a métrica de interesse e faço a otimização de hiperparâmteros\n",
    "# a fim de encontrar o melhor modelo para o problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando 'Bag of Words'\n",
    "\n",
    "df = pd.read_csv('spam_ham.csv')\n",
    "\n",
    "df.text = df.text.str.lower().str.replace(r'[^\\w\\s]+', ' ').str.split()\n",
    "\n",
    "mensagens_juntas = reduce(lambda x, y: x + y, df.text)\n",
    "palavras_comuns = Counter(mensagens_juntas).most_common(100)\n",
    "palavras_comuns = [i[0] for i in palavras_comuns]\n",
    "\n",
    "x = []\n",
    "for mensagem in df.text:\n",
    "    contagem = {p: 0 for p in palavras_comuns}\n",
    "    \n",
    "    for palavra in mensagem:\n",
    "        if palavra in contagem:\n",
    "            contagem[palavra] += 1\n",
    "    \n",
    "    x.append(contagem)\n",
    "    \n",
    "x = pd.DataFrame(x)\n",
    "y = df.type.apply(lambda x: int(x == 'spam'))\n",
    "\n",
    "# pré processamento\n",
    "x = MinMaxScaler().fit_transform(x)\n",
    "\n",
    "# split de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# métrica de avaliação: fbeta\n",
    "# caso positivo: mensagem spam\n",
    "# caso negativo: mensagem não spam\n",
    "\n",
    "# a métrica 'fbeta' é a média harmônica ponderada da 'precisão' e da 'revocação', estas que representam\n",
    "# respectivamente, o número de verdadeiros positivos sobre o total de predições positivas(uma precisão \n",
    "# alta indica que ocorreram poucos falsos positivos) e o número de verdadeiros positivos sobre o total de \n",
    "# elementos positivos (reflete quantos dos casos positivos foram detectados)\n",
    "\n",
    "# optei pela 'fbeta', posto que, do meu ponto de vista, a prioridade é minimizar o número de falsos positivos\n",
    "# (dizer que uma mensagem não spam é spam), uma vez que a ocorrência dos mesmos poderia incorrer na perda de \n",
    "# informações importantes (por exemplo, no caso de uma conta de e-mail, uma mensagem importante, \n",
    "# incorretamente classificada como spam é direcionada à quarentena; o usuário não acessa esta seção de sua \n",
    "# conta e deixa de receber o conteúdo daquele e-mail), no entanto, o modelo não seria útil, caso trouxesse\n",
    "# zero falsos positivos, mas sua revocação fosse muito baixa (por exemplo, o modelo acusa apenas um elemento \n",
    "# como positivo e acerta, resultando em uma precisão perfeita, mas a base de dados continha cem casos positivos, \n",
    "# resultando em uma revocação de 0.1), portanto, uma solução que julgo adequada é uma métrica que leve em \n",
    "# consideração estes dois fatores, a porporção de falsos positivos e a proporção de positivos detectados, \n",
    "# mas possa priorizar a não ocorrência de falsos positivos(por isso que o peso da precisão, no cálculo da média,\n",
    "# é maior)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# o motivo de se tirar a média harmônica, e não a média aritmética: \n",
    "\n",
    "# a primeira pune valores extremos, por exemplo, se fôssemos calcular o f1-score(média harmônica entre precisão\n",
    "# e revocação, onde estas possuem o mesmo peso), para um f1 alto, é necessário que tanto a precisão quanto a \n",
    "# revocação sejam altas; tendo valores x = 1, y = 0.1, a média aritmética é 0.55, já a média harmônica é 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionário contendo algoritmos e seus repectivos hiperparâmetros; este será percorrido por um 'for'\n",
    "\n",
    "model_params = {\n",
    "                 'mnb':{'model': MultinomialNB(),\n",
    "                       'params':{} },\n",
    "                 \n",
    "                 'dt':{'model': DecisionTreeClassifier(),\n",
    "                       'params':{'max_depth':[4, 8, 12, 16], \n",
    "                                 'min_samples_split':[2, 4, 8, 12], \n",
    "                                 'min_samples_leaf':[2, 4, 6, 8, 12]} },\n",
    "                        \n",
    "                 'lr':{'model': LogisticRegression(), \n",
    "                      'params':{'solver':['lbfgs', 'liblinear'],\n",
    "                                'class_weight':[None, 'balanced']} },\n",
    "                        \n",
    "                 'knn':{'model': KNeighborsClassifier(),\n",
    "                       'params':{'n_neighbors':[2, 3, 5, 7, 9, 11, 13, 15, 17, 19],\n",
    "                                 'weights':['uniform', 'distance']} }\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb : 81.59%\n",
      "{}\n",
      "\n",
      "dt : 87.81%\n",
      "{'max_depth': 8, 'min_samples_leaf': 2, 'min_samples_split': 4}\n",
      "\n",
      "lr : 88.05%\n",
      "{'class_weight': None, 'solver': 'liblinear'}\n",
      "\n",
      "knn : 89.17%\n",
      "{'n_neighbors': 9, 'weights': 'distance'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV rodando com dados de treino apenas\n",
    "\n",
    "my_scorer = make_scorer(fbeta_score, beta = 0.5)\n",
    "scores = []\n",
    "for m_name, m_prms in model_params.items():\n",
    "    gscv =  GridSearchCV(m_prms['model'], m_prms['params'], cv = 5, scoring = my_scorer)\n",
    "    gscv.fit(X_train, y_train)\n",
    "    \n",
    "    scores.append({\n",
    "                     'model': m_name,\n",
    "                     'best_score': gscv.best_score_,\n",
    "                     'best_params': gscv.best_params_\n",
    "                 })\n",
    "    \n",
    "for i in scores:\n",
    "    print('{0} : {1}%\\n{2}\\n'.format(i['model'], round((i['best_score'] * 100), 2),i['best_params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight = None, solver = 'liblinear')\n",
    "knn = KNeighborsClassifier(n_neighbors = 9, weights = 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors: 89.13%\n",
      "LogisticRegression: 86.59%\n"
     ]
    }
   ],
   "source": [
    "# dados de teste nos dois melhores modelos, com os melhores hiperparâmetros, de acordo com o grid search\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 9, weights = 'distance') \n",
    "knn.fit(X_train, y_train)\n",
    "knn_score = fbeta_score(y_pred = knn.predict(X_test), y_true = y_test, beta = 0.5)\n",
    "\n",
    "lr = LogisticRegression(class_weight = None, solver = 'liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "lr_score = fbeta_score(y_pred = lr.predict(X_test), y_true = y_test, beta = 0.5)\n",
    "\n",
    "print('KNeighbors: {0}%\\nLogisticRegression: {1}%'.format(round((knn_score * 100), 2), \n",
    "                                                          round((lr_score * 100), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opto pelo algortimo 'KNeighbors', com hiperparâmetros: n_neighbors = 9 e weights = 'distance',\n",
    "# posto que este obteve o 'score' mais alto e se super-ajustou menos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
